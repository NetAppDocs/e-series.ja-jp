---
permalink: config-linux/nvme-roce-setup-host-side-task.html 
sidebar: sidebar 
keywords: express linux configuration, software configuration, linux host, E2800, E5700, EF300, EF600, E-Series, eseries 
summary: RoCE 環境で NVMe イニシエータを設定するには、 rdma-core および nvme-CLI パッケージをインストールして設定し、イニシエータの IP アドレスを設定し、ホストで NVMe-oF レイヤを設定します。 
---
= Eシリーズ- LinuxのホストでのRoCE経由のNVMeイニシエータの設定
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
RoCE 環境で NVMe イニシエータを設定するには、 rdma-core および nvme-CLI パッケージをインストールして設定し、イニシエータの IP アドレスを設定し、ホストで NVMe-oF レイヤを設定します。

.作業を開始する前に
互換性のある最新のRHEL 8、RHEL 9、SUSE Linux Enterprise Server 12、または15サービスパックのオペレーティングシステムを実行している必要があります。最新の要件については、 https://mysupport.netapp.com/matrix["NetApp Interoperability Matrix Tool で確認できます"^]をご覧ください。

.手順
. RDMA パッケージと nvme-CLI パッケージをインストールします。
+
* SLES 12 または SLES 15 *

+
[listing]
----

# zypper install rdma-core
# zypper install nvme-cli
----
+
*RHEL 8、およびRHEL 9*。

+
[listing]
----

# yum install rdma-core
# yum install nvme-cli
----
. RHEL 8およびRHEL 9の場合は、ネットワークスクリプトをインストールする。
+
* RHEL 8 *

+
[listing]
----
# yum install network-scripts
----
+
* RHEL 9*

+
[listing]
----
# yum install NetworkManager-initscripts-updown
----
. ホストのNQNを取得します。アレイに対してホストを設定する際に使用します。
+
[listing]
----
# cat /etc/nvme/hostnqn
----
. NVMe over RoCE の接続に使用されるイーサネットポートで、 IPv4 の IP アドレスを設定します。ネットワークインターフェイスごとに、そのインターフェイスに対応する変数を含む構成スクリプトを作成します。
+
この手順で使用する変数は、サーバハードウェアとネットワーク環境に基づいています。変数には 'IPADDR' と 'gateway' が含まれます次に、 SLES および RHEL の例を示します。

+
* SLES 12 および SLES 15 *

+
以下の内容を含むサンプル・ファイル'/etc/sysconfig/network/ifcfg-eth4'を作成します

+
[listing]
----
BOOTPROTO='static'
BROADCAST=
ETHTOOL_OPTIONS=
IPADDR='192.168.1.87/24'
GATEWAY='192.168.1.1'
MTU=
NAME='MT27800 Family [ConnectX-5]'
NETWORK=
REMOTE_IPADDR=
STARTMODE='auto'
----
+
次に'/etc/sysconfig/network/ifcfg-eth5`のサンプルファイルを作成します

+
[listing]
----
BOOTPROTO='static'
BROADCAST=
ETHTOOL_OPTIONS=
IPADDR='192.168.2.87/24'
GATEWAY='192.168.2.1'
MTU=
NAME='MT27800 Family [ConnectX-5]'
NETWORK=
REMOTE_IPADDR=
STARTMODE='auto'
----
+
* RHEL 8 *

+
以下の内容を含むサンプル・ファイル'/etc/sysconfig/network-scripts/ifcfg-eth4'を作成します

+
[listing]
----
BOOTPROTO='static'
BROADCAST=
ETHTOOL_OPTIONS=
IPADDR='192.168.1.87/24’
GATEWAY='192.168.1.1'
MTU=
NAME='MT27800 Family [ConnectX-5]'
NETWORK=
REMOTE_IPADDR=
STARTMODE='auto'
----
+
次に'/etc/sysconfig/network-scripts/ifcfg-eth5`のサンプルファイルを作成します

+
[listing]
----
BOOTPROTO='static'
BROADCAST=
ETHTOOL_OPTIONS=
IPADDR='192.168.2.87/24'
GATEWAY='192.168.2.1'
MTU=
NAME='MT27800 Family [ConnectX-5]'
NETWORK=
REMOTE_IPADDR=
STARTMODE='auto'
----
+
* RHEL 9*

+
を使用します `nmtui` 接続を活動化および編集するためのツール。以下はサンプルファイルです `/etc/NetworkManager/system-connections/eth4.nmconnection` ツールは次のものを生成します。

+
[listing]
----

[connection]
id=eth4
uuid=<unique uuid>
type=ethernet
interface-name=eth4

[ethernet]
mtu=4200

[ipv4]
address1=192.168.1.87/24
method=manual

[ipv6]
addr-gen-mode=default
method=auto

[proxy]
----
+
以下はサンプルファイルです `/etc/NetworkManager/system-connections/eth5.nmconnection` ツールは次のものを生成します。

+
[listing]
----

[connection]
id=eth5
uuid=<unique uuid>
type=ethernet
interface-name=eth5

[ethernet]
mtu=4200

[ipv4]
address1=192.168.2.87/24
method=manual

[ipv6]
addr-gen-mode=default
method=auto

[proxy]
----
. ネットワークインターフェイスを有効にします。
+
[listing]
----

# ifup eth4
# ifup eth5
----
. ホストで NVMe-oF レイヤを設定します。次のファイルを `/etc/modules-load.d/` をロードするには `nvme_rdma` カーネルモジュールと、再起動後もカーネルモジュールが常にオンになっていることを確認します。
+
[listing]
----

# cat /etc/modules-load.d/nvme_rdma.conf
  nvme_rdma
----
. ホストをリブートします。
+
を確認するには `nvme_rdma` カーネルモジュールがロードされました。次のコマンドを実行します。

+
[listing]
----
# lsmod | grep nvme
nvme_rdma              36864  0
nvme_fabrics           24576  1 nvme_rdma
nvme_core             114688  5 nvme_rdma,nvme_fabrics
rdma_cm               114688  7 rpcrdma,ib_srpt,ib_srp,nvme_rdma,ib_iser,ib_isert,rdma_ucm
ib_core               393216  15 rdma_cm,ib_ipoib,rpcrdma,ib_srpt,ib_srp,nvme_rdma,iw_cm,ib_iser,ib_umad,ib_isert,rdma_ucm,ib_uverbs,mlx5_ib,qedr,ib_cm
t10_pi                 16384  2 sd_mod,nvme_core
----

